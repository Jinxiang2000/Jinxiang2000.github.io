<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mathematical Modeling on Jinxiang Ma</title>
    <link>http://localhost:1313/categories/mathematical-modeling/</link>
    <description>Recent content in Mathematical Modeling on Jinxiang Ma</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>© 2025 </copyright>
    <lastBuildDate>Fri, 20 Jun 2025 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/categories/mathematical-modeling/feed.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Impact of Memory Size on Quasi-Newton Methods</title>
      <link>http://localhost:1313/projects/quasi-netwon/</link>
      <pubDate>Fri, 20 Jun 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/projects/quasi-netwon/</guid>
      <description>&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;In large-scale optimization problems, especially those arising in machine learning and engineering design, traditional second-order methods like Newton’s method can be prohibitively expensive due to the need to compute and store the full Hessian matrix. Quasi-Newton methods provide a powerful alternative by approximating the Hessian matrix iteratively using only first-order information, significantly reducing computational cost while maintaining fast convergence.&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
